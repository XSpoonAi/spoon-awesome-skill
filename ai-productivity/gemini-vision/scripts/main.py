"""
Skill: Gemini Vision Analyzer
Author: Moxan
Description: Analyzes images using Google Gemini 2.0 Flash with proxy support, retry logic, and mock mode.
Dependencies: google-generativeai, pydantic, Pillow
Track: AI-Enhanced Productivity
"""

import base64
import json
import logging
import os
import random
import time
from typing import Optional, Dict, Any

try:
    import google.generativeai as genai
    from pydantic import BaseModel
    from PIL import Image
    import io
except ImportError:
    # Allow import without dependencies for inspection
    pass

logger = logging.getLogger(__name__)

class VisionAnalysisResult(BaseModel):
    """Result of image analysis."""
    is_valid: bool
    label: Optional[str] = None
    description: Optional[str] = None
    confidence: float = 0.0
    details: Optional[dict] = None

async def analyze_image(
    image: bytes, 
    prompt: str, 
    valid_labels: Optional[list] = None,
    model_name: str = "gemini-2.5-flash"
) -> dict:
    """
    Analyze an uploaded image using Gemini Vision API.

    Features:
    - Proxy support via HTTPS_PROXY/HTTP_PROXY
    - Retry logic for 429/Quota errors
    - Mock mode via MOCK_VISION env var
    - JSON response parsing

    Args:
        image: Raw image bytes
        prompt: Analysis prompt instruction
        valid_labels: Optional list of valid labels to validate against
        model_name: Gemini model to use (default: gemini-2.5-flash)

    Returns:
        dict with analysis results
    """
    
    # Mock mode for testing
    if os.getenv("MOCK_VISION", "false").lower() == "true":
        selected_label = random.choice(valid_labels) if valid_labels else "mock_object"
        logger.info(f"[MOCK MODE] Returning mock analysis: {selected_label}")
        return {
            "is_valid": True,
            "label": selected_label,
            "description": "This is a mock description generated in test mode.",
            "confidence": 0.95,
            "details": {
                "features": ["mock_feature_1", "mock_feature_2"],
                "notes": "Generated by MOCK_VISION mode"
            }
        }

    try:
        # Configure proxy for Gemini API access
        proxy = os.getenv("HTTPS_PROXY") or os.getenv("HTTP_PROXY")
        if proxy:
            os.environ["HTTP_PROXY"] = proxy
            os.environ["HTTPS_PROXY"] = proxy
            os.environ["GRPC_PROXY"] = proxy
            logger.info(f"Using proxy for Gemini API: {proxy}")

        # Configure Gemini API key
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            logger.warning("GEMINI_API_KEY not set")
            return {"is_valid": False, "description": "API Key missing"}

        # WORKAROUND: Disable SSL verification for Proxy envs if needed
        import ssl
        import urllib3
        urllib3.disable_warnings()
        try:
            _create_unverified_https_context = ssl._create_unverified_context
        except AttributeError:
            pass
        else:
            ssl._create_default_https_context = _create_unverified_https_context
        
        genai.configure(api_key=api_key, transport="rest")

        # Configure Gemini
        model = genai.GenerativeModel(model_name)
        logger.info(f"Using Gemini model: {model_name}")

        # Encode image
        image_data = base64.b64encode(image).decode('utf-8')

        # Append JSON formatting instruction to prompt
        json_instruction = """
        Please respond in strict JSON format with the following structure:
        {
            "is_valid": true/false,
            "label": "classification_label",
            "description": "detailed description",
            "confidence": 0.0-1.0,
            "details": {
                "features": [],
                "issues": [],
                "recommendations": []
            }
        }
        """
        full_prompt = f"{prompt}\n\n{json_instruction}"

        # Call API with retry
        max_retries = 3
        retry_delay = 5

        for attempt in range(max_retries):
            try:
                response = model.generate_content([
                    full_prompt,
                    {"mime_type": "image/jpeg", "data": image_data}
                ])
                break
            except Exception as e:
                error_str = str(e).lower()
                if "429" in error_str or "resource exhausted" in error_str:
                    if attempt < max_retries - 1:
                        wait_time = retry_delay * (attempt + 1)
                        logger.warning(f"Rate limited, waiting {wait_time}s...")
                        time.sleep(wait_time)
                        continue
                raise

        # Parse response
        response_text = response.text
        if "```json" in response_text:
            response_text = response_text.split("```json")[1].split("```")[0]
        elif "```" in response_text:
            response_text = response_text.split("```")[1].split("```")[0]

        result = json.loads(response_text.strip())

        # Optional label validation
        if valid_labels and result.get("label") and result["label"] not in valid_labels:
            result["label"] = None
            result["is_valid"] = False
            result["description"] = "Unrecognized object type"

        return result

    except Exception as e:
        logger.error(f"Vision analysis error: {e}")
        return {
            "is_valid": False,
            "description": f"Analysis error: {str(e)}",
            "confidence": 0.0
        }

# Skill registration decorator (mock implementation for portability)
def skill(name: str):
    def decorator(func):
        func._skill_name = name
        return func
    return decorator

@skill("gemini_vision_analyze")
async def vision_analyze(image: bytes, prompt: str) -> dict:
    """Wrapper for SpoonOS skill execution"""
    return await analyze_image(image, prompt)
