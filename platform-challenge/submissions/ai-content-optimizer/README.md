# AI Content Optimizer - Complete Guide

## Content Quality Analysis

### Analyze Content Quality

```python
from content_optimizer import ContentQualityAnalyzer

analyzer = ContentQualityAnalyzer()

content = """
# Machine Learning Basics

Machine learning is a subset of artificial intelligence...

## Key Concepts
- Supervised Learning: Training with labeled data
- Unsupervised Learning: Finding patterns without labels
- Reinforcement Learning: Learning through rewards

Example: A spam classifier trained on labeled emails.

Conclusion: ML enables computers to learn from data.
"""

quality = analyzer.analyze_quality(content)
print(f"Overall Score: {quality['overall_quality_score']}/10")
print(f"Issues: {quality['issues']}")
print(f"Recommendations: {quality['recommendations']}")
```

### Tokenize for AI

```python
tokens = analyzer.tokenize_for_ai(content)
print(f"Words: {tokens['word_count']}")
print(f"Estimated Tokens: {tokens['estimated_tokens']}")
print(f"Vocabulary: {tokens['vocabulary_size']} unique words")
```

### Extract Training Pairs

```python
training_pairs = analyzer.extract_training_pairs(content)
for pair in training_pairs:
    print(f"Q: {pair['question']}")
    print(f"A: {pair['answer']}")
```

---

## Dataset Optimization

### Analyze Dataset

```python
from content_optimizer import DatasetOptimizer

optimizer = DatasetOptimizer()

dataset = [
    {"text": "Machine learning basics", "label": "introduction", "quality": 0.9},
    {"text": "Deep learning explained", "label": "advanced", "quality": 0.95},
    {"text": "ML algorithms", "label": "advanced", "quality": 0.85},
    # ... more samples
]

optimization = optimizer.optimize_dataset(dataset)
print(f"Dataset Size: {optimization['original_size']}")
print(f"Issues: {optimization['issues']}")
print(f"Optimizations: {optimization['optimizations']}")
```

### Remove Duplicates

```python
result = optimizer.remove_duplicates(dataset)
print(f"Duplicates Removed: {result['duplicates_removed']}")
print(f"Deduplication Rate: {result['deduplication_rate']:.1%}")
```

### Balance Classes

```python
balanced = optimizer.balance_classes(dataset, 'label')
print(f"Original: {result['original_size']} samples")
print(f"Balanced: {result['balanced_size']} samples")
print(f"Distribution: {result['class_distribution']}")
```

### Filter Quality Data

```python
filtered = optimizer.filter_quality_data(dataset, min_quality_score=0.85)
print(f"Retained: {filtered['retention_rate']:.1%}")
print(f"Removed: {filtered['removed']} low-quality entries")
```

---

## Model Hyperparameter Optimization

### Analyze Current Config

```python
from content_optimizer import ModelOptimizer

model_optimizer = ModelOptimizer()

config = {
    "model_type": "neural_network",
    "layers": [128, 64, 32],
    "activation": "relu",
    "learning_rate": 0.01,
    "batch_size": 32,
    "epochs": 50,
    "optimizer": "adam"
}

analysis = model_optimizer.analyze_model_config(config)
print(f"Optimization Score: {analysis['optimization_score']}/10")
for issue in analysis['issues']:
    print(f"Issue: {issue}")
for rec in analysis['recommendations']:
    print(f"Suggestion: {rec}")
```

### Get Hyperparameter Suggestions

```python
# For small dataset (< 1000 samples)
suggestions_small = model_optimizer.suggest_hyperparameters(500)
print("For 500 samples:")
print(f"  Learning Rate: {suggestions_small['suggested_hyperparameters']['learning_rate']}")
print(f"  Batch Size: {suggestions_small['suggested_hyperparameters']['batch_size']}")
print(f"  Epochs: {suggestions_small['suggested_hyperparameters']['epochs']}")

# For large dataset (> 10000 samples)
suggestions_large = model_optimizer.suggest_hyperparameters(50000)
print("\nFor 50,000 samples:")
print(f"  Learning Rate: {suggestions_large['suggested_hyperparameters']['learning_rate']}")
print(f"  Batch Size: {suggestions_large['suggested_hyperparameters']['batch_size']}")
print(f"  Epochs: {suggestions_large['suggested_hyperparameters']['epochs']}")
```

---

## Complete ML Pipeline Example

```python
from content_optimizer import ContentOptimizer

optimizer = ContentOptimizer()

# 1. Analyze training content quality
training_content = """
Comprehensive guide to machine learning...
"""

content_opt = optimizer.quality_analyzer.analyze_quality(training_content)
print(f"Content Quality: {content_opt['overall_quality_score']}/10")

# 2. Prepare and optimize dataset
raw_dataset = [
    {"text": "...", "label": "A"},
    {"text": "...", "label": "B"},
    # ...
]

dataset_opt = optimizer.dataset_optimizer.remove_duplicates(raw_dataset)
balanced_dataset = optimizer.dataset_optimizer.balance_classes(raw_dataset, 'label')
quality_dataset = optimizer.dataset_optimizer.filter_quality_data(raw_dataset, 0.8)

print(f"Dataset Size: {len(raw_dataset)} â†’ {len(quality_dataset)}")

# 3. Suggest model configuration
model_config = optimizer.model_optimizer.suggest_hyperparameters(len(quality_dataset))
print(f"Learning Rate: {model_config['suggested_hyperparameters']['learning_rate']}")
print(f"Batch Size: {model_config['suggested_hyperparameters']['batch_size']}")

# 4. Overall optimization
complete_analysis = optimizer.optimize_all(training_content, quality_dataset, model_config)
print(f"Recommendation: {complete_analysis['overall_recommendation']}")
```

---

## Best Practices

### Content Preparation
- **Aim for 7+/10 quality score** - High-quality content improves model performance
- **Include examples** - Helps model understand context
- **Clear structure** - Use headings, lists, and paragraphs
- **Consistent formatting** - Maintains readability

### Dataset Optimization
- **Remove duplicates** - Prevents data leakage and overfitting
- **Balance classes** - Ensures fair representation
- **Filter low quality** - Improves training data quality
- **Validate distribution** - Check for class imbalance

### Model Configuration
- **Match dataset size** - Adjust hyperparameters accordingly
- **Use early stopping** - Prevents overfitting
- **Monitor validation** - Track performance during training
- **Document settings** - Maintain reproducibility

---

## Scoring Details

### Quality Scoring (0-10)
| Score | Interpretation |
|-------|-----------------|
| 9-10 | Excellent - Publication ready |
| 7-8 | Good - Suitable for training |
| 5-6 | Fair - Needs improvement |
| 3-4 | Poor - Significant issues |
| 0-2 | Very Poor - Not suitable |

### Component Scoring
- **Readability**: How easy to understand (short sentences, common words)
- **Completeness**: Coverage of topic (examples, explanations, conclusions)
- **Consistency**: Uniform formatting and style
- **Clarity**: Absence of jargon, clear explanations
- **Structure**: Organized with headings, lists, paragraphs

---

## Troubleshooting

| Issue | Solution |
|-------|----------|
| Low content quality score | Simplify language, add structure, include examples |
| High duplicate rate | Review data collection process |
| Class imbalance | Use balancing feature or weighted loss |
| Model not converging | Try lower learning rate or smaller batch size |

---

## Summary

The AI Content Optimizer provides:
- **Quality Analysis**: Evaluate content for AI training
- **Dataset Preparation**: Clean and optimize datasets
- **Hyperparameter Tuning**: Data-driven parameter suggestions
- **Complete Pipeline**: Integrated optimization framework

Use these tools to prepare high-quality datasets for machine learning pipelines.
